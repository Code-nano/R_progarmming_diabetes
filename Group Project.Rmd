---
title: "WQD7004 Group Project"
output: html_document
runtime: shiny
---

## Group Member:

1)  Muhammad Imran Haiqal bin Azmi (17113547)
2)  Tasslim Bin Mansoor Ali (23056322)
3)  Muhammad Adib Bin Mohd Akbar (17119253)
4)  Muhammad Aiman bin Zolkifli (22080779)
5)  Nur Qistina binti Roslan (22089573)

## Title

Risk of Diabetes Prediction

## Introduction

Diabetes is a chronic disease associated with individuals inability to effectively regulate the glucose level in the blood, leading to diminished quality of life and reduced longevity. Individuals that are diagnosed with diabetes often suffer many health complications including heart disease, chronic kidney disease, nerve damage and mental health issues. The challenge is that diabetes patients are frequently diagnosed in the later stages of the disease when significant complications have already developed. Therefore, there is a need for a highly accurate model that can establish strong relationships between individuals' background factors and risk of diabetes.

## Dataset

**Diabetes Health Indicators Dataset**

Source: <https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data>

## Objective

1)  To identify and quantify how certain individuals background (smoking habit, blood pressure, cholesterol levels) contribute to the progression of diabetes.
2)  To classifies individuals based on their risk of developing diabetes, considering their background.
3)  To predict the progression rate of diabetes in individuals using key health indicators (Cholesterol, BP, Stroke and Heart Disease)

------------------------------------------------------------------------

## Libraries

```{r}
library(tidyverse)
library(ggplot2)
library(caret)
library(dplyr)
library(Metrics)
library(e1071)
library(rpart)
library(pROC)
library(corrplot)
library(randomForest)
library(klaR)
```

------------------------------------------------------------------------

## Load our Dataset

```{r}
data<-read_csv("diabetes.csv")
```

------------------------------------------------------------------------

## Data Understanding

```{r}
# Summary of dataset
glimpse(data)

# Structure of dataset
str(data)

# Check if there is any NA value
colSums(is.na(data))

# Check if there is any empty string value
colSums(data=="")
```

```{r}
# Checking duplicated values 
anyDuplicated(data)
# Remove the duplicated row 
duplicate_rows <- duplicated(data) 
data <- data[!duplicate_rows, ]
# Checking duplicated values 
anyDuplicated(data)
```

------------------------------------------------------------------------

## Exploratory Data Analysis (EDA)

```{r}
# Load the corrplot package
library(corrplot)

# Generate a random dataset for demonstration purposes
set.seed(123)

# Compute the correlation matrix
cor_matrix <- cor(data)

# Create a correlation heatmap
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust", tl.cex = 0.7)

# Exploratory Data Analysis (EDA)
# New Column to determine the diabetes
data$diabetes_binary <- ifelse(data$Diabetes_012 > 0, "Diabetic", "Non-Diabetic")
data$diabetes_binary <- factor(data$diabetes_binary)

# Count the values of 
category_count <- table(data$diabetes_binary)
print(category_count)

# Plot the bar chart
barplot(category_count, main = "Bar Chart of Diabetes", xlab = "Categories", ylab = "Frequency", col = "skyblue")

# Plot a pie chart
pie(category_count, main = "Pie Chart of Diabetes", col = rainbow(length(category_count)))

# Relation of Diabetes with Blood Pressure
contingency_table <- table(data$diabetes_binary, data$HighBP)
df_contingency <- as.data.frame.matrix(contingency_table)
barplot(as.matrix(df_contingency), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and BP Levels",
        xlab = "Diabetes Status", ylab = "Count")


# Relation of High Cholestrol with Diabetes
cholesterol_counts <- table(data$HighChol)
print(cholesterol_counts)
pie(cholesterol_counts, main = "Pie Chart: Cholesterol Levels",
    labels = c("Normal Cholesterol", "High Cholesterol"),
    col = c("red", "lightblue"))
pie(category_count, main = "Pie Chart of Diabetes", col = rainbow(length(category_count)))

# Relation of High BP with Diabetes
contingency_table1 <- table(data$diabetes_binary, data$HighChol)
df_contingency1 <- as.data.frame.matrix(contingency_table1)
barplot(as.matrix(df_contingency1), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and BP Levels",
        xlab = "Diabetes Status", ylab = "Count")

# Binning
bins <- c(0, 18.5, 25, 30, 35, 40, Inf)
# Create a new variable "BMI_category" based on the bins
data$BMI_category <- cut(data$BMI, bins, labels = c("Underweight", "Normal", "Overweight", "Obese I", "Obese II", "Obese III"))

# Filtering the dataset to diabetes patients
#data <- data %>% filter(data$Diabetes_012==1 | data$Diabetes_012==2 )



# Regression Model
# Exploratory Data Analysis
# BMI vs General Health
ggplot(data, aes(x = GenHlth, fill = BMI_category)) +
  geom_bar(position = "dodge", stat = "count") +
  labs(title = "Bar Plot of BMI Categories vs. General Health",
       x = "BMI Category",
       y = "Count") +
  theme_minimal()

#Smoker vs diabetes
smoker_counts <- table(data$Smoker)
print(smoker_counts)
pie(smoker_counts,  main = "Smoking pie chart",col = rainbow(length(smoker_counts)))
legend("topright", c("Non-Smoker","Smoker"), cex = 0.8,
       fill = rainbow(length(smoker_counts)))

contingency_table2 <- table(data$diabetes_binary, data$Smoker)
df_contingency2 <- as.data.frame.matrix(contingency_table2)
df_contingency2
barplot(as.matrix(df_contingency2), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and Smoking",
        xlab = "Diabetes Status", ylab = "Count")
# According to this data, smoking has minor effect on diabetes

#Heavy Alcohol Consumption vs Diabetes
alcohol_counts <- table(data$HvyAlcoholConsump)
print(alcohol_counts)
pie(alcohol_counts,  main = "alcohol pie chart",col = rainbow(length(alcohol_counts)))
legend("topright", c("Non HvyAlcoholConsumption","HvyAlcoholConsumption"), cex = 0.8,
       fill = rainbow(length(alcohol_counts)))

contingency_table3 <- table(data$diabetes_binary, data$HvyAlcoholConsump)
df_contingency3 <- as.data.frame.matrix(contingency_table3)
df_contingency3
barplot(as.matrix(df_contingency3), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and Heavy Alcohol Consumption",
        xlab = "Diabetes Status", ylab = "Frequency")
#According to this data, there is insufficient data to prove that heavy alcohol effects diabetes.

#Lifestyle
#physactivity
contingency_table4 <- table(data$diabetes_binary, data$PhysActivity)
df_contingency4 <- as.data.frame.matrix(contingency_table4)
df_contingency4
barplot(as.matrix(df_contingency4), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and PhysActivity",
        xlab = "Diabetes Status", ylab = "Count")

#Lifestyle
#fruits
contingency_table5 <- table(data$diabetes_binary, data$Fruits)
df_contingency5 <- as.data.frame.matrix(contingency_table5)
df_contingency5
barplot(as.matrix(df_contingency5), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and Fruits",
        xlab = "Diabetes Status", ylab = "Count")

#Lifestyle
#Veggies
contingency_table6 <- table(data$diabetes_binary, data$Veggies)
df_contingency6 <- as.data.frame.matrix(contingency_table6)
df_contingency6
barplot(as.matrix(df_contingency4), beside = TRUE, legend.text = TRUE, col = c("red", "blue"),
        main = "Relationship between Diabetes and Veggies",
        xlab = "Diabetes Status", ylab = "Count")

#Lifestyle practises such as physical activity and consumption of fruits and veggies reduces the risk of diabetes

#Gender and diabetes
ggplot(data, aes(x = Sex, fill = diabetes_binary)) +
  geom_bar(position = "dodge", color = "black") +
  labs(title = 'Diabetes Disease Frequency for Sex',
       x = 'Sex (0 = Female, 1 = Male)',
       y = 'Frequency') +
  scale_fill_manual(values = c('#AA1111', '#1CA53B'),
                    name = "Diabetes Status",
                    labels = c("Have Diabetic", "Healthy")) +
  theme_minimal()
#We can see that female are not just more diabetic than men but they are also healthier

#Relationship between bmi and diabetes
ggplot(data, aes(x = BMI, fill = diabetes_binary)) +
  geom_bar(position = "dodge", color = "black") +
  labs(title = 'Diabetes Disease Frequency for BMI',
       x = 'BMI',
       y = 'Frequency') +
  scale_fill_manual(values = c('#AA1111', '#1CA53B'),
                    name = "Diabetes Status",
                    labels = c("Have Diabetic", "Healthy")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

#People range between 24-33 are more prone to have diabetes

#relationship between income and diabetes
ggplot(data, aes(x = Income, fill = diabetes_binary)) +
  geom_bar(position = "dodge", color = "black") +
  labs(title = 'Diabetes Disease Frequency for Income',
       x = 'Income',
       y = 'Frequency') +
  scale_fill_manual(values = c('#AA1111', '#1CA53B'),
                    name = "Diabetes Status",
                    labels = c("Have Diabetic", "Healthy")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

#We can say that people with higher income are more diabetic

```

------------------------------------------------------------------------

## Modelling and evaluation

### Regression Methods

#### Train-test Preparation

```{r}
# possible number of health complication (0-4)
#Linear Regression of Health Complication with Diabetes
# Filtering the dataset to non-diabetes and pre-diabetes patients
data <- data %>% filter(data$Diabetes_012==0 | data$Diabetes_012==1 )

# Mutate new column that combine all health complications
data <- mutate(data, "Health_Complication" = HighChol + HighBP + Stroke + HeartDiseaseorAttack)

set.seed(123)  # Set a random seed for reproducibility
train_index <- createDataPartition(data$Health_Complication, p = 0.6, list = FALSE)
train_data <- data[train_index, ]
temp_data <- data[-train_index, ]

# Create validation and test sets
validation_index <- createDataPartition(temp_data$Health_Complication, p = 0.5, list = FALSE)
validation_data <- temp_data[validation_index, ]
test_data <- temp_data[-validation_index, ]



```

------------------------------------------------------------------------

#### Linear Regression Modelling

```{r}
# Define the model formula
model_comp <- Health_Complication ~ BMI + Smoker + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + GenHlth + NoDocbcCost + MentHlth + PhysHlth + DiffWalk + Sex + Age
model_formula <- model_comp

# Train the linear regression model
linear_model <- lm(model_formula, data = train_data)

# Summarize the model 
summary(linear_model)

# Make predictions on the test set
predictions <- predict(linear_model, newdata = test_data)

# Evaluate the model performance
mse <- mean((predictions - test_data$Health_Complication)^2)
rmse <- sqrt(mse)
print(paste("Mean Squared Error:", mse))
print(paste("Root Mean Squared Error:", rmse))

```

### Decision Tree Regression

```{r}
#Decision Tree Regression
tree_model <- rpart(model_comp , data = train_data, method = "anova")
tree_prediction <- predict(tree_model, newdata = test_data)
mse <- mean((tree_prediction - test_data$Health_Complication)^2)
rmse <- sqrt(mse)
print(paste("Mean Squared Error:", mse))
print(paste("Root Mean Squared Error:", rmse))
```

### Classification method

#### Kth Near Neighbor Modelling and Evaluation

```{r}
# Split the data for modelling
diabetes <-read.csv("diabetes.csv")  
#check for duplicated rows
anyDuplicated(diabetes)
#collect duplicated rows
duplicate_rows <- duplicated(diabetes)
duplicate_rows
#drop duplicated rows
diabetes <- diabetes[!duplicate_rows,]
glimpse(diabetes)
#re check the duplicated rows
anyDuplicated(diabetes)
 
#convert data to factor
diabetes$Diabetes_012 <- as.factor(diabetes$Diabetes_012)
glimpse(diabetes)
 
#split data 80% train, 20% test
trainIndex<-createDataPartition(diabetes$Diabetes_012, p=0.8, list=F)
data_train<-diabetes[trainIndex,]
data_test<-diabetes[-trainIndex,]  
x_test <- data_test[,2:22]
y_test <- data_test[,1]
```

##### KNN Modelling

```{r}
#Modelling KNN
model <- train(Diabetes_012~., data=data_train, method = "knn")
# make predictions using KNN
predictionsKNN <- predict(model, x_test)
#Confusion matrix using KNN
cmKNN<-confusionMatrix(predictionsKNN, y_test)
#KNN ROC 
ctrlKNN <- trainControl(method = "repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary)
ctrlKNN
```

##### KNN Evaluation

```{r}
#k-fold cross validation
# k-fold
diabetes <- data.frame(diabetes)
train_control <- trainControl(method="cv", number=10)
modelKNN1 <- train(Diabetes_012~., data=diabetes, trControl=train_control, method="knn")
predictKNN1 <- predict(modelKNN1, x_test)
cmKNN1<-confusionMatrix(predictKNN1, y_test)
cmKNN1
```

### Random Forest

```{r}
#RANDOM FOREST
# modelling random forest 
modelRF <- randomForest(Diabetes_012~., data=data_train)
#make predictions using random forest
predictionsRF <- predict(modelRF, x_test)
#Confusion matrix using random forest
cmRF<-confusionMatrix(predictionsRF, y_test)
cmRF
 
ctrlRF <- trainControl(method = "repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary)
ctrlRF
result3d
```

##### Random Forest Evaluation

```{r}
#k-fold cross validation
# k-fold
diabetes <- data.frame(diabetes)
train_control <- trainControl(method="cv", number=10)
modelRF1 <- train(Diabetes_012~., data=diabetes, trControl=train_control, method="rf")
predictRF1 <- predict(modelRF1, x_test)
cmRF1<-confusionMatrix(predictRF1, y_test)
cmRF1
```

```{r}
length(predictions)
length(testData$Diabetes_012)

```

------------------------------------------------------------------------

### Conclusion

In conclusion, we have predicted the progression rate of diabetes in individuals using key health indicators (Cholesterol, BP, Stroke and Heart Disease) for our regression section. Based on our observation, the Support Vector Machine model is the best model to predict the progression rate of diabetes in individuals with the lowest MSE and RMSE value. We have performed two classification method which is KNN and Random Forest to classify diabetes given the independent variables. Also, we have conducted cross validation method and ROC to measure the performance of the classification model.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R Markdown document is made interactive using Shiny. Unlike the more traditional workflow of creating static reports, you can now create documents that allow your readers to change the assumptions underlying your analysis and see the results immediately.

To learn more, see [Interactive Documents](http://rmarkdown.rstudio.com/authoring_shiny.html).
